import os
import pandas as pd
from difflib import get_close_matches
import requests
import xml.etree.ElementTree as ET
from dotenv import load_dotenv
from app.external_api.law_api import fetch_law_detail_by_mst
from config.settings import OLLAMA_API_URL, OLLAMA_MODEL

load_dotenv()
LAW_API_KEY = os.getenv("LAW_API_KEY")

# CSV ë¡œë”©
law_df = pd.read_csv("data/laws.csv", encoding="utf-8-sig", skiprows=1)
law_df.columns = law_df.columns.str.strip()

assert "ë²•ë ¹ëª…" in law_df.columns and "ë²•ë ¹MST" in law_df.columns, "CSVì— í•„ìš”í•œ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤."

# í‚¤ì›Œë“œ ê¸°ë°˜ ë²•ë ¹ëª… â†’ MST ì¶”ì¶œ
def normalize(text):
    return text.replace(" ", "").strip().lower()

def find_law_mst_by_keyword(keyword: str):
    norm_keyword = normalize(keyword)
    law_df["ì •ê·œí™”ë²•ë ¹ëª…"] = law_df["ë²•ë ¹ëª…"].astype(str).apply(normalize)

    exact = law_df[law_df["ì •ê·œí™”ë²•ë ¹ëª…"] == norm_keyword]
    if not exact.empty:
        row = exact.iloc[0]
        return {"ë²•ë ¹ëª…": row["ë²•ë ¹ëª…"], "MST": str(int(row["ë²•ë ¹MST"]))}

    # get_close_matchesì— ì •ê·œí™”ëœ ë¦¬ìŠ¤íŠ¸ ì‚¬ìš©
    match = get_close_matches(norm_keyword, law_df["ì •ê·œí™”ë²•ë ¹ëª…"].tolist(), n=1, cutoff=0.6)
    if match:
        row = law_df[law_df["ì •ê·œí™”ë²•ë ¹ëª…"] == match[0]].iloc[0]
        return {"ë²•ë ¹ëª…": row["ë²•ë ¹ëª…"], "MST": str(int(row["ë²•ë ¹MST"]))}
    return None

# í†µí•© ì§ˆì˜ í•¨ìˆ˜
def run_rag_query_with_api(collection, user_query: str):
    law = find_law_mst_by_keyword(user_query)
    print("ğŸ“Œ law ê°ì²´:", law)
    api_context = ""

    if law:
        api_context = fetch_law_detail_by_mst(law["MST"])
        print("ğŸ“„ [DEBUG] API ì‘ë‹µ ìš”ì•½ ë‚´ìš©:")
        print(api_context[:500] if api_context else "[ì‘ë‹µ ì—†ìŒ]")
        if not api_context.strip():
            print("âš ï¸ API ì‘ë‹µì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")

    # RAG ë¬¸ì„œ ê²€ìƒ‰
    results = collection.query(query_texts=[user_query], n_results=5)
    if not results["documents"] or not results["documents"][0]:
        rag_chunks = ["[RAG ë¬¸ì„œê°€ ê²€ìƒ‰ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.]"]
        ids, metadatas, distances = [], [], []
    else:
        rag_chunks = results["documents"][0]
        ids = results["ids"][0]
        metadatas = results["metadatas"][0]
        distances = results["distances"][0]

    rag_text = "\n".join([f"- {chunk.strip()}" for chunk in rag_chunks[:5]])

    # ë¬¸ë§¥ êµ¬ì„±
    full_context = f"""
[ì™¸ë¶€ì •ë³´: êµ­ê°€ë²•ë ¹ì •ë³´ API ìš”ì•½]
{api_context}

[ë‚´ë¶€ì •ë³´: RAG ê²€ìƒ‰ ë¬¸ì„œ]
{rag_text}
""".strip()

    prompt = f"""
ë‹¹ì‹ ì€ ë²•ë ¹ ì§ˆë¬¸ì— ë‹µí•˜ëŠ” í•œêµ­ì–´ LLM ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
ì•„ë˜ì˜ ë¬¸ë§¥ì„ ì°¸ê³ í•˜ì—¬ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì •í™•íˆ ë‹µí•˜ì‹­ì‹œì˜¤.

# ë¬¸ë§¥:
{full_context}

# ì§ˆë¬¸:
{user_query}

# ë‹µë³€:
""".strip()

    # LLM ì§ˆì˜ (Ollama)
    try:
        response = requests.post(
            OLLAMA_API_URL,
            json={
                "model": OLLAMA_MODEL,
                "prompt": prompt,
                "stream": False
            }
        )
        response.raise_for_status()
        return {
            "query": user_query,
            "answer": response.json().get("response", "[ì‘ë‹µ ì—†ìŒ]"),
            "law_name": law["ë²•ë ¹ëª…"] if law else None,
            "api_summary": api_context,
            "rag_context": rag_chunks,
            "ids": ids,
            "metadatas": metadatas,
            "distances": distances
        }

    except requests.RequestException as e:
        raise Exception(f"Ollama API ìš”ì²­ ì‹¤íŒ¨: {str(e)}")

    except ValueError:
        raise Exception(f"Ollama ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨: {response.text}")
